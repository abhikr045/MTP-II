\chapter{Results and Discussions}

\section{Conclusions}
Redaction is an important procedure in order to preserve privacy and has applications in many domains like dataset preparation, remote exam settings, etc. In this work, we presented the feature preserving approach to face redaction, which is very crucial to undertake before the essential features are lost during redaction. We demonstrated the feature-preserving nature of our approaches on 3-way and 2-way gaze classification and facial proximity preservation via several experiments and ablation studies. \\

The post-classification approach is the most straightforward way for gaze classification in the presence of an already trained regression model. These models do not generalize well across datasets due to domain shift in data distribution. In order to learn a robust model, the model needs to be trained (i.e., tuned) on the target dataset, which enables it to adapt to the data distribution shift between the source and target dataset. The tuning process can be done on very small data and still train the model for state-of-the-art accuracy values. \\

We demonstrated via various redaction schemes (blurred or blacked out face or eyes) the robustness of our feature-preserving face redaction. The results show that gaze classification on redacted images is as accurate as that performed on un-redacted images. The ablation studies with redaction of eyes demonstrated the importance of eyes for gaze classification and emphasized on the fact that the model is able to learn from the eye crops. We also explored the explicit need for training a model on redacted faces, and via elaborate experiments, we concluded that tuning the model with visible faces works equally well for gaze prediction on redacted faces. \\

The direct classification approach, where a classifier is trained from scratch, showed that to learn robust features, a significant amount of data is required for training. Also, the results of the classifier model trained on UK data and tested on START data demonstrated that, unlike the regression model, the classification model generalizes well across datasets and is able to overcome the domain shift in data distribution arising due to the differences in the source and target datasets.

Finally, we utilized a 2-way gaze classification model for the task of 3-way gaze classification without requiring any training and still obtaining high accuracy. This demonstrates the robustness of our 2-way classifier and the ability of the model to predict the left and right gaze with high confidence. We also preserved the relative face proximity feature by using the facial landmarks and demonstrated the expected trend of proximity versus the time of the video to be matching our results.

We also calculated facial proximity values by using the facial landmarks output by Retina Face and employing the PnP algorithm. We demonstrated the trend of proximity values on videos as well as on the images with measured ground truths. Another approach to facial proximity calculation is discussed in the Appendix.


\section{Future Scope}
We mentioned in section 4.3.1 that the post-classification approach suffers from device dependencies issues. We established this by training a regression model on MIT data and testing for classification on filtered 2-way UK data. In order to further strengthen the proof, one could also establish the device dependency by training a regression model on filtered 2-way UK data and testing for classification on MIT data. Note that in order to achieve this, one would first need to extract the ground-truth stimulus coordinates displayed on the 3-way gaze application.\\

We have demonstrated the robustness of our methods via several model tuning experiments mentioned in the previous chapters. Another approach to gaze preserving face redaction could be to build a neural network architecture that just takes the 3-D facial landmark features and the face grid as inputs and attempts to predict the gaze classes. Specifically, one could train and test the gaze classification task with only landmarks and a face grid supplied as input features (i.e., no face and eyes). This would result in a significant reduction in computation cost as the convolution layers would then not be required in the network architecture.