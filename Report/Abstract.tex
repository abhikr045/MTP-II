%============================= abs.tex================================
\begin{Abstract}
Analysis of mental health and development from videos is a relatively newer field in scene understanding from computer vision algorithms. A vital feature utilized for such behavioral analyses is the gaze of the subject. For instance, the so-called Preferential Looking and the Anti-saccade tasks adopted in the Autism community track the gaze for 2-Way and 3-Way Gaze Classification, respectively. Another important feature for gauging the subject's attention is the proximity of the face to the camera of the recording device. To this end, we prepare a Gaze Tracking dataset to facilitate mental health assessments.\\

It is imperative to preserve the identities of the subjects before releasing the dataset, which leads to Face Redaction. It is the task of hiding all the faces present in the dataset. There are several ways in which the faces can be redacted, e.g., by blurring or blackening out all the faces, swapping the face with the face of another person, or overlaying a mesh of facial landmarks. In this work, we achieve face redaction by blurring or blackening out the faces. Face redaction makes it difficult to extract gaze and facial features from redacted faces. In this work, we propose a \textbf{Feature Preserving Redaction} mechanism that preserves the important features required for further analyses. Many applications demand such a feature preserving nature of redaction, e.g., releasing a dataset while preserving the privacy of the subjects, hiding the identity of a public figure or students appearing in a remote exam before analyzing the scene, etc. Since these videos are recorded in an unproctored environment, we systematically demonstrate the versatility of our methods in an uncurated setting via several experiments.


%
%
%
%
%
\end{Abstract}
%=======================================================================

